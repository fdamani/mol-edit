7.14
	- implemented evalute_func using greedy sampling
		- delta qed
		- percent valid decoded
	TODO:
		- for QED task, compute percent of decoded compounds that are in the [.9, 1.0] range (conditioned on valid decoding)
		- percent decoded successfully.
		- implement alternative decoders
			- sampler
			- beam search
		- plots for everything.

7.12
	- validation metrics (use validation data)
		- teacher forcing at validation time to measure NLL.
		- compute delta QED for decoded samples use this as validation metric.
			- try a few different versions 
				- greedy sampling 
				- sample multiple times and average.

7.11
	- refactored seq2seq code
	- new alphabet class ("Lang")
	- new training code
	- new evaluation code
	- encoder and decoder (no attention) nets implemented
	- successfully overfitting to 1k training pairs.

	Next:
		- measure validation performance
		- scale to larger dataset
		- implement attention-based decoders
7.8.19
	TODO:
		- run regression model (smiles and selfies) for logp06 and qed and compare r^2 values
		- implement seq2seq model (see wengong jin implementation)
		- implement variational seq2seq model (see wengong jin implementation)
		- how do these compare to their work? compare on selfies representation.
		- generate a complete set of potency mmpa training datasets
			- varying similarity thresholds
			- varying levels of potency
			- write script to run this.

	DONE:
		- generated regression training data for penalized logp and qed


7.3.19
	TODO:
		- generate training data (view different versions-- moderate and high tanimoto simlarity, inactive to active, inactive to moderately active, inactive to highly active)
		- implement seq2seq model
		- generate suite of evaluation methods to evaluate results.



7.2.19
	- mini-batching using packed sequence.
	- SELFIES-based representation
		- 498 compounds can not be encoded into SELFIES (see mol-edit/output/pot_pred_selfies/)
		- r^2 score on validation is .75 while SMILES was ~.83.
			- SELFIES vocab size is 88 while SMILES is 38
				- current implementation does not do any additional regularization (besides GRU cell)
				- 2x number of parameters -> discrepancy might be explained by overfitting.
			- remove 498 invalid SELFIES compounds from SMILES dataset?
	- initial mmpa training data generation
		- compute tanimoto simlarity based on morgan fingerprint.
		- initial strategy to generate training data:
			- find pairs between inactive (potency = -3.) and active (potency != -3.) with high tanimoto similarity.
				- use rest of inactive compounds (235k) to form pairs. -> keep high tanimoto similarity.
7.1.19
	- overfit RNN to small dataset
	- run on full dataset and show validation / train loss
	- minor optimizations:
		- pass as input to forward full word and have self.rnn return final hidden state
		- mini-batching
6.26.19
	- implemented RNN for potency prediction
6.25.19
	- Predict potency conditioned on structure
		- Implement RNN
		- Compare SMILES and SELFIES based representations.
