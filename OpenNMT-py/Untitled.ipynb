{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import onmt\n",
    "import onmt.inputters\n",
    "import onmt.modules\n",
    "import onmt.utils\n",
    "from onmt.utils.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_fields = torch.load(\"data/data.vocab.pt\")\n",
    "\n",
    "src_text_field = vocab_fields[\"src\"].base_field\n",
    "src_vocab = src_text_field.vocab\n",
    "src_padding = src_vocab.stoi[src_text_field.pad_token]\n",
    "\n",
    "tgt_text_field = vocab_fields['tgt'].base_field\n",
    "tgt_vocab = tgt_text_field.vocab\n",
    "tgt_padding = tgt_vocab.stoi[tgt_text_field.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 100\n",
    "rnn_size = 500\n",
    "# Specify the core model.\n",
    "\n",
    "encoder_embeddings = onmt.modules.Embeddings(emb_size, len(src_vocab),\n",
    "                                             word_padding_idx=src_padding)\n",
    "\n",
    "encoder = onmt.encoders.RNNEncoder(hidden_size=rnn_size, num_layers=1,\n",
    "                                   rnn_type=\"LSTM\", bidirectional=True,\n",
    "                                   embeddings=encoder_embeddings)\n",
    "\n",
    "decoder_embeddings = onmt.modules.Embeddings(emb_size, len(tgt_vocab),\n",
    "                                             word_padding_idx=tgt_padding)\n",
    "decoder = onmt.decoders.decoder.InputFeedRNNDecoder(\n",
    "    hidden_size=rnn_size, num_layers=1, bidirectional_encoder=True, \n",
    "    rnn_type=\"LSTM\", embeddings=decoder_embeddings)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = onmt.models.model.NMTModel(encoder, decoder)\n",
    "model.to(device)\n",
    "\n",
    "# Specify the tgt word generator and loss computation module\n",
    "model.generator = nn.Sequential(\n",
    "    nn.Linear(rnn_size, len(tgt_vocab)),\n",
    "    nn.LogSoftmax(dim=-1)).to(device)\n",
    "\n",
    "loss = onmt.utils.loss.NMTLossCompute(\n",
    "    criterion=nn.NLLLoss(ignore_index=tgt_padding, reduction=\"sum\"),\n",
    "    generator=model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "torch_optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optim = onmt.utils.optimizers.Optimizer(\n",
    "    torch_optimizer, learning_rate=lr, max_grad_norm=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data\n",
    "from itertools import chain\n",
    "train_data_file = \"data/data.train.0.pt\"\n",
    "valid_data_file = \"data/data.valid.0.pt\"\n",
    "train_iter = onmt.inputters.inputter.DatasetLazyIter(dataset_paths=[train_data_file],\n",
    "                                                     fields=vocab_fields,\n",
    "                                                     batch_size=50,\n",
    "                                                     batch_size_multiple=1,\n",
    "                                                     batch_size_fn=None,\n",
    "                                                     device=device,\n",
    "                                                     is_train=True,\n",
    "                                                     pool_factor=1,\n",
    "                                                     repeat=True)\n",
    "\n",
    "valid_iter = onmt.inputters.inputter.DatasetLazyIter(dataset_paths=[valid_data_file],\n",
    "                                                     fields=vocab_fields,\n",
    "                                                     batch_size=10,\n",
    "                                                     batch_size_multiple=1,\n",
    "                                                     batch_size_fn=None,\n",
    "                                                     device=device,\n",
    "                                                     is_train=False,\n",
    "                                                     pool_factor=1,\n",
    "                                                     repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_manager = onmt.utils.ReportMgr(\n",
    "    report_every=2, start_time=None, tensorboard_writer=None)\n",
    "trainer = onmt.Trainer(model=model,\n",
    "                       train_loss=loss,\n",
    "                       valid_loss=loss,\n",
    "                       optim=optim,\n",
    "                       report_manager=report_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMTModel(\n",
       "  (encoder): RNNEncoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (make_embedding): Sequential(\n",
       "        (emb_luts): Elementwise(\n",
       "          (0): Embedding(24997, 100, padding_idx=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rnn): LSTM(100, 250, bidirectional=True)\n",
       "  )\n",
       "  (decoder): InputFeedRNNDecoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (make_embedding): Sequential(\n",
       "        (emb_luts): Elementwise(\n",
       "          (0): Embedding(35820, 100, padding_idx=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0)\n",
       "    (rnn): StackedLSTM(\n",
       "      (dropout): Dropout(p=0.0)\n",
       "      (layers): ModuleList(\n",
       "        (0): LSTMCell(600, 500)\n",
       "      )\n",
       "    )\n",
       "    (attn): GlobalAttention(\n",
       "      (linear_in): Linear(in_features=500, out_features=500, bias=False)\n",
       "      (linear_out): Linear(in_features=1000, out_features=500, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (generator): Sequential(\n",
       "    (0): Linear(in_features=500, out_features=35820, bias=True)\n",
       "    (1): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<onmt.utils.statistics.Statistics at 0x12099b898>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(train_iter=train_iter,\n",
    "              train_steps=5,\n",
    "              valid_iter=valid_iter,\n",
    "              valid_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SENT 0: ['Parliament', 'Does', 'Not', 'Support', 'Amendment', 'Freeing', 'Tymoshenko']\n",
      "PRED 0: .\n",
      "PRED SCORE: -4.5354\n",
      "\n",
      "\n",
      "SENT 0: ['Today', ',', 'the', 'Ukraine', 'parliament', 'dismissed', ',', 'within', 'the', 'Code', 'of', 'Criminal', 'Procedure', 'amendment', ',', 'the', 'motion', 'to', 'revoke', 'an', 'article', 'based', 'on', 'which', 'the', 'opposition', 'leader', ',', 'Yulia', 'Tymoshenko', ',', 'was', 'sentenced', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.1179\n",
      "\n",
      "\n",
      "SENT 0: ['The', 'amendment', 'that', 'would', 'lead', 'to', 'freeing', 'the', 'imprisoned', 'former', 'Prime', 'Minister', 'was', 'revoked', 'during', 'second', 'reading', 'of', 'the', 'proposal', 'for', 'mitigation', 'of', 'sentences', 'for', 'economic', 'offences', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.2003\n",
      "\n",
      "\n",
      "SENT 0: ['In', 'October', ',', 'Tymoshenko', 'was', 'sentenced', 'to', 'seven', 'years', 'in', 'prison', 'for', 'entering', 'into', 'what', 'was', 'reported', 'to', 'be', 'a', 'disadvantageous', 'gas', 'deal', 'with', 'Russia', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.3216\n",
      "\n",
      "\n",
      "SENT 0: ['The', 'verdict', 'is', 'not', 'yet', 'final;', 'the', 'court', 'will', 'hear', 'Tymoshenko', '&apos;s', 'appeal', 'in', 'December', '.']\n",
      "PRED 0: .\n",
      "PRED SCORE: -4.4584\n",
      "\n",
      "\n",
      "SENT 0: ['Tymoshenko', 'claims', 'the', 'verdict', 'is', 'a', 'political', 'revenge', 'of', 'the', 'regime;', 'in', 'the', 'West', ',', 'the', 'trial', 'has', 'also', 'evoked', 'suspicion', 'of', 'being', 'biased', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.0905\n",
      "\n",
      "\n",
      "SENT 0: ['The', 'proposal', 'to', 'remove', 'Article', '365', 'from', 'the', 'Code', 'of', 'Criminal', 'Procedure', ',', 'upon', 'which', 'the', 'former', 'Prime', 'Minister', 'was', 'sentenced', ',', 'was', 'supported', 'by', '147', 'members', 'of', 'parliament', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.2718\n",
      "\n",
      "\n",
      "SENT 0: ['Its', 'ratification', 'would', 'require', '226', 'votes', '.']\n",
      "PRED 0: .\n",
      "PRED SCORE: -4.4559\n",
      "\n",
      "\n",
      "SENT 0: ['Libya', '&apos;s', 'Victory']\n",
      "PRED 0: \n",
      "PRED SCORE: -4.5469\n",
      "\n",
      "\n",
      "SENT 0: ['The', 'story', 'of', 'Libya', '&apos;s', 'liberation', ',', 'or', 'rebellion', ',', 'already', 'has', 'its', 'defeated', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.2152\n",
      "\n",
      "\n",
      "SENT 0: ['Muammar', 'Kaddafi', 'is', 'buried', 'at', 'an', 'unknown', 'place', 'in', 'the', 'desert', '.', 'Without', 'him', ',', 'the', 'war', 'is', 'over', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.0842\n",
      "\n",
      "\n",
      "SENT 0: ['It', 'is', 'time', 'to', 'define', 'the', 'winners', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.1800\n",
      "\n",
      "\n",
      "SENT 0: ['As', 'a', 'rule', ',', 'Islamists', 'win', 'in', 'the', 'country;', 'the', 'question', 'is', 'whether', 'they', 'are', 'the', 'moderate', 'or', 'the', 'radical', 'ones', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -3.9930\n",
      "\n",
      "\n",
      "SENT 0: ['The', 'transitional', 'cabinet', 'declared', 'itself', 'a', 'follower', 'of', 'the', 'customary', 'Sharia', 'law', ',', 'of', 'which', 'we', 'have', 'already', 'heard', '.']\n",
      "PRED 0: .\n",
      "PRED SCORE: -4.3469\n",
      "\n",
      "\n",
      "SENT 0: ['Libya', 'will', 'become', 'a', 'crime', 'free', 'country', ',', 'as', 'the', 'punishment', 'for', 'stealing', 'is', 'having', 'one', '&apos;s', 'hand', 'amputated', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.2297\n",
      "\n",
      "\n",
      "SENT 0: ['Women', 'can', 'forget', 'about', 'emancipation;', 'potential', 'religious', 'renegades', 'will', 'be', 'executed;', 'etc', '.']\n",
      "PRED 0: .\n",
      "PRED SCORE: -4.4909\n",
      "\n",
      "\n",
      "SENT 0: ['Instead', 'of', 'a', 'dictator', ',', 'a', 'society', 'consisting', 'of', 'competing', 'tribes', 'will', 'be', 'united', 'by', 'Koran', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.2325\n",
      "\n",
      "\n",
      "SENT 0: ['Libya', 'will', 'be', 'in', 'an', 'order', 'we', 'cannot', 'imagine', 'and', 'surely', 'would', 'not', 'ask', 'for', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.1852\n",
      "\n",
      "\n",
      "SENT 0: ['However', ',', 'our', 'lifestyle', 'is', 'neither', 'unique', 'nor', 'the', 'best', 'one', 'and', 'would', 'not', ',', 'most', 'probably', ',', 'be', 'suitable', 'for', ',', 'for', 'example', ',', 'the', 'people', 'of', 'Libya', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.0021\n",
      "\n",
      "\n",
      "SENT 0: ['In', 'fact', ',', 'it', 'is', 'a', 'wonder', 'that', 'the', 'Islamic', 'fighters', 'accepted', 'help', 'from', 'the', 'nonbelievers', '.']\n",
      "PRED 0: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "PRED SCORE: -4.1672\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c34d66fd48dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     trans_batch = translator.translate_batch(\n\u001b[1;32m     22\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_vocabs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_vocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         attn_debug=False)\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrans\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranslations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/projects/mol-edit/OpenNMT-py/onmt/translate/translator.py\u001b[0m in \u001b[0;36mtranslate_batch\u001b[0;34m(self, batch, src_vocabs, attn_debug)\u001b[0m\n\u001b[1;32m    521\u001b[0m                     \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                     \u001b[0mn_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_best\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                     return_attention=attn_debug or self.replace_unk)\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/projects/mol-edit/OpenNMT-py/onmt/translate/translator.py\u001b[0m in \u001b[0;36m_translate_batch\u001b[0;34m(self, batch, src_vocabs, max_length, min_length, ratio, n_best, return_attention)\u001b[0m\n\u001b[1;32m    672\u001b[0m                 batch_offset=beam._batch_offset)\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m             \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m             \u001b[0many_beam_is_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many_beam_is_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/projects/mol-edit/OpenNMT-py/onmt/translate/beam_search.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, log_probs, attn)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mcurr_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         torch.topk(curr_scores,  self.beam_size, dim=-1,\n\u001b[0;32m--> 151\u001b[0;31m                    out=(self.topk_scores, self.topk_ids))\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Recover log probs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import onmt.translate\n",
    "\n",
    "src_reader = onmt.inputters.str2reader[\"text\"]\n",
    "tgt_reader = onmt.inputters.str2reader[\"text\"]\n",
    "scorer = onmt.translate.GNMTGlobalScorer(alpha=0.7, \n",
    "                                         beta=0., \n",
    "                                         length_penalty=\"avg\", \n",
    "                                         coverage_penalty=\"none\")\n",
    "gpu = 0 if torch.cuda.is_available() else -1\n",
    "translator = onmt.translate.Translator(model=model, \n",
    "                                       fields=vocab_fields, \n",
    "                                       src_reader=src_reader, \n",
    "                                       tgt_reader=tgt_reader, \n",
    "                                       global_scorer=scorer,\n",
    "                                       gpu=gpu)\n",
    "builder = onmt.translate.TranslationBuilder(data=torch.load(valid_data_file), \n",
    "                                            fields=vocab_fields)\n",
    "\n",
    "\n",
    "for batch in valid_iter:\n",
    "    trans_batch = translator.translate_batch(\n",
    "        batch=batch, src_vocabs=[src_vocab],\n",
    "        attn_debug=False)\n",
    "    translations = builder.from_batch(trans_batch)\n",
    "    for trans in translations:\n",
    "        print(trans.log(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSENT 10: ['Muammar', 'Kaddafi', 'is', 'buried', 'at', 'an', 'unknown', 'place', 'in', 'the', 'desert', '.', 'Without', 'him', ',', 'the', 'war', 'is', 'over', '.']\\nPRED 10: . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\nPRED SCORE: -4.0842\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[0].log(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
